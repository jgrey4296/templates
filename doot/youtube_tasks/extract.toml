## extract.toml -*- mode: Conf[TOML] -*-

[[locations]]
youtube        = "/media/john/big_ex/datasets/youtube/data"
yt_raw         = "raw"
extracted      = "extracted"
extract_tars   = "extract_tars"
extract_backup = "/media/john/big_ex/datasets/youtube/extracted"
extract_output = "/media/john/data/datasets/todo/youtube"



[[tasks.yt]]
name = "joint"
doc = ["unpack then extract from a tar"]
ctor = "job"
cli     = [
        { name="target", type="str", default="{youtube!p}/northernlion.tar.gz", positional=true },
        { name="out",    type="str", default="unpacked", positional=true },
]
actions = [
    {do="job.expand", template="yt::unpack",  inject={copy=["target", "out"]}, update_="unpack"},
    {do="job.expand", template="yt::extract", inject={copy=["target"]}, update_="extract"},
    {do="job.chain.->", unpack={literal=[], by-name=[]}},
    {do="job.queue", from_multi_=["update", "extract"]},
]

[[tasks.yt]]
name    = "unpack"
version = "0.1"
doc     = ["unpack {target.tar.gz} into raw/{out}"]
ctor    = "task"
cli     = [
        { name="target", type="str", default="{youtube!p}/northernlion.tar.gz", positional=true },
        { name="out",    type="str", default="unpacked", positional=true },
]
actions = [
        {do="path.elements", from="{target!p}"},
        {do="dir?", args=["{yt_raw!p}/{out}"]},
        {do="shell", args=["tar", "-xf", "{target!p}", "--directory", "{yt_raw!p}/{out}"]},
        {do="doot.actions.io:ListFiles", from="{yt_raw!p}/{out}", update_="flist"},
        {do="write!", from_="flist", to="{yt_raw!p}/{fstem}_files.list"}
]

[[tasks.yt]]
name                     = "extract"
version                  = "0.1"                # <str>
doc                      = ["Walk an unpacked youtube data directory, extracting to into {extracted}/{pstem}.jsonnl"]
ctor                     = "job"
cli                      = [{ name="target", type="str", default="northernlion", positional=true }]
queue_behaviour          = "default"
recursive                = false
exts                     = [".json"]
roots                    = ["{yt_raw!p}/{target}"]
jsonl                    = "{extracted!p}/{pstem}.jsonl"
select_limit             = -1
cleanup         = [
    {do="dootle.actions.say:say", args=["complete"]},
    {do="pathParts", from_="target"},
    # gz and backup
    {do="tar!", file_="jsonl", to="{extract_tars!p}/{pstem}.jsonl.tar"},
    {do="copy", from="{extract_tars!p}/{pstem}.jsonl.tar", to="{extract_backup!p}/{pstem}.jsonl.tar"},
    {do="copy", from="{extract_tars!p}/{pstem}.jsonl.tar", to="{extract_output!p}/{pstem}.jsonl.tar"},
    # delete raw
    {do="delete!", args=["{yt_raw!p}/{target}"], recursive=true}
]
actions                  = [
    {do="job.walk",   update_="files"}, # walk,
    {do="job.expand", base_="sub_actions", from_="files", inject={copy=["jsonl"], replace=["fpath"]}, update_="tasks" },
    {do="job.limit",  from_="tasks", count_="select_limit"},
    {do="job.inject.path.elements", onto_="tasks", key="fpath"},
    {do="job.queue", from_="tasks"}, # queue
]
sub_actions              = [
    {do="ext?", ext=".json"},
    {do="taskcode.util:skip_if_too_big", maxMB="1"},
    # TODO : skip if too big
    # load the json
    {do="json.read", from_="fpath", update_="json"},
    # extract the data
    {do="taskcode.json:reduce_video_metadata", from_="json", update_="reduction"},
    # add to db/jsonl list. TODO: track id's, for resume
    {do="json.nl.write", from_="reduction", to_="jsonl"}
]
